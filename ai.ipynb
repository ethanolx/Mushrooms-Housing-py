{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd006e46f44bb844bdd55de1af887732b14e875f5b0d2374a3f4b9484cbcb737e08",
   "display_name": "Python 3.8.5  ('.venv': pipenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "06e46f44bb844bdd55de1af887732b14e875f5b0d2374a3f4b9484cbcb737e08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "source": [
    "# AIML CA1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import General Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical Dependency\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation Dependency\n",
    "import pandas as pd\n",
    "\n",
    "# Graphing Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning Dependencies\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Preservation Dependency\n",
    "import pickle\n",
    "\n",
    "# Miscellaneous Dependencies\n",
    "from typing import Callable, Dict, Union    # static typing\n",
    "from warnings import filterwarnings         # warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide Warnings\n",
    "filterwarnings(action='ignore')"
   ]
  },
  {
   "source": [
    "## Part A > Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How is your prediction task defined? And what is the meaning of the\n",
    "output variable?\n",
    "\n",
    "```\n",
    "    The task is to predict if a mushroom of the agaricus lepiota family is edible or poisonous,\n",
    "    given its properties (i.e. cap-shape, odor, etc.)\n",
    "\n",
    "    The output variable is class, and its possible values carry the respective meanings:\n",
    "    'edible':       the mushroom is safe for consumption\n",
    "    'poisonous':    do not consume the mushroom\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import Data\n",
    "\n",
    "Load data about edibility of gilled mushrooms of the agaricus lepiota family"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How do you represent your data as features?\n",
    "\n",
    "```\n",
    "    The features are represented as columns in a pandas DataFrame\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   Did you bring in any additional sources of data?\n",
    "\n",
    "```\n",
    "    No, no external data sources were used\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extraction import extract_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_mushrooms() -> pd.DataFrame:\n",
    "    # Extract raw content of ./data/agaricus-lepiota.names file\n",
    "    metadata: str\n",
    "    with open('./data/agaricus-lepiota.names') as f:\n",
    "        metadata = f.read()\n",
    "\n",
    "    # Extract attributes from metadata\n",
    "    attrs = extract_attributes(metadata, r'7\\. Attribute Information:.*\\n((.|\\n)*)8\\. Missing')\n",
    "\n",
    "    # Extract column names to be used for dataframe\n",
    "    cols = attrs.keys()\n",
    "\n",
    "    # Create the dataframe from ./data/agaricus-lepiota.data file,\n",
    "    #   using column names derived from ./data/agaricus-lepiota.names file\n",
    "    df = pd.read_csv(\n",
    "        filepath_or_buffer='./data/agaricus-lepiota.data',\n",
    "        sep=',',\n",
    "        header=0,\n",
    "        names=cols\n",
    "    )\n",
    "\n",
    "    # Expand attribute codes to their full definitions\n",
    "    for col in cols:\n",
    "        df[col].replace(to_replace=attrs[col] ,inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = load_mushrooms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_whole = df.drop(labels='class', axis=1)\n",
    "y_whole = df['class']\n",
    "X_build, X_final, y_build, y_final = train_test_split(X_whole, y_whole, test_size=0.2, random_state=1)\n",
    "df_build = pd.concat(objs=(X_build, y_build), axis=1)"
   ]
  },
  {
   "source": [
    "#### Inspect Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect top 10 rows of the dataset\n",
    "df.head(n=10)"
   ]
  },
  {
   "source": [
    "#### Summarize Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect overview of the dataset\n",
    "df.info()"
   ]
  },
  {
   "source": [
    "### Pre-Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   Did you process the features in any way?\n",
    "\n",
    "```\n",
    "    Yes, the features underwent (feature) selection and (one-hot) encoding\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Exploratory Data Analysis (EDA)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to keep track of variables to be removed\n",
    "drop_cols = []"
   ]
  },
  {
   "source": [
    "Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isna().sum(axis=0), end='\\n')\n",
    "\n",
    "# Note that stalk-root has missing attributes (denoted as 'missing')\n",
    "# In fact, approx. 31% of the records have missing data for stalk-root\n",
    "stalk_dist = df['stalk-root'].value_counts()\n",
    "print((stalk_dist / stalk_dist.sum()).round(2))\n",
    "\n",
    "# Course of action - drop column\n",
    "drop_cols.append('stalk-root')"
   ]
  },
  {
   "source": [
    "Redundant Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect unqiue counts of the individual features\n",
    "print(df.describe().transpose().sort_values(by='unique', ascending=False))\n",
    "\n",
    "# Note that veil-type has only one value,\n",
    "#   hence it is a redundant feature\n",
    "print('\\n', 'Unique values for \\'veil-type\\': ', pd.unique(df['veil-type'].values), sep='')\n",
    "\n",
    "# Course of action - drop column\n",
    "drop_cols.append('veil-type')"
   ]
  },
  {
   "source": [
    "Inspect the distribution of the target variable (class: edible/poisonous)\n",
    "\n",
    "The data seems rather balanced, with an almost even distribution of edible and poisonous mushrooms.\n",
    "This means that the inherent bias of the machine learning model is low.\n",
    "\n",
    "For example, if there was much more data for edible mushrooms, the machine learning model would predict edible mushrooms much more precisely than poisonous ones."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import format_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1A():\n",
    "    global df\n",
    "    ax, fig = plt.subplots(figsize=(7, 5))\n",
    "    ax = sns.countplot(data=df, x='class', palette='deep')\n",
    "    ax.set_ylim(top=5000)\n",
    "    ax.set_title(label='General Data Distribution')\n",
    "    ax.set_ylabel(ylabel='Number of Records')\n",
    "    ax.set_yticklabels(labels=format_label(ax.get_yticks() / 1000, lambda s: f'{round(s)}k'))\n",
    "    ax.set_xlabel(xlabel='Type')\n",
    "    total_count = df.shape[0]\n",
    "    for p in ax.patches:\n",
    "        x = p.get_x()\n",
    "        y = p.get_height()\n",
    "        ax.annotate(text=f'{y} ({y / total_count * 100:.1f}%)', xy=(x + 0.23, y + 70))\n",
    "\n",
    "plot_1A()"
   ]
  },
  {
   "source": [
    "Inspect correlation between the independent variables and the target variable (class)\n",
    "\n",
    "The plot on the left depicts a chi2-based correlation between the distribution of the independent variables and the 'class' target variable.\n",
    "\n",
    "This is how it works:\n",
    "*   The more the data is evenly distributed between 'edible' and 'poisonous' for a certain attribute, the less it is correlated to edibility\n",
    "*   For example, among 1,000 mushrooms with pink gills, if 500 are edible and 500 are poisonous, then pink gills is not a good indicator of whether a mushroom is poisonous\n",
    "*   Any deviation from 50% distribution would hint some form of correlation\n",
    "\n",
    "No columns/features were removed solely based on their correlations with the target ('class')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_1B():\n",
    "    global df\n",
    "    for i in df.drop(labels='class', axis=1).columns.values:\n",
    "        fig, (corr_plot, freq_plot) = plt.subplots(ncols=2, figsize=(14, 6))\n",
    "        ct = pd.crosstab(index=df['class'], columns=df[i])\n",
    "        distr = df.groupby(i).count().iloc[:,0]\n",
    "        proportion = ((ct.loc['edible']) / distr) - 0.5\n",
    "        corr = pd.DataFrame(proportion.reset_index())\n",
    "        sns.barplot(data=corr, x=i, y=0, ax=corr_plot, color='grey')\n",
    "        sns.countplot(data=df.sort_values(by=i), x=i, hue='class', hue_order=['edible', 'poisonous'], ax=freq_plot, palette='turbo')\n",
    "        fig.suptitle(t=f'{i.upper()}')\n",
    "        corr_plot.set_title(label='Correlation (chi2-based)')\n",
    "        corr_plot.set_ylim((-0.6, 0.6))\n",
    "        corr_plot_x_lim = corr_plot.get_xlim()\n",
    "        corr_plot.set_yticks(ticks=np.arange(-0.5, 0.6, 0.1))\n",
    "        corr_plot.set_yticklabels(labels=np.round(corr_plot.get_yticks() + 0.5, 1))\n",
    "        corr_plot.set_ylabel(ylabel='Correlation')\n",
    "        corr_plot.set_xticklabels(labels=corr_plot.get_xticklabels(), rotation=30)\n",
    "        corr_plot.annotate(text='Tends to be \\'edible\\'', xy=((corr_plot_x_lim[0] + corr_plot_x_lim[1]) / 2, 0.55), ha='center', color='green')\n",
    "        corr_plot.annotate(text='Tends to be \\'poisonous\\'', xy=((corr_plot_x_lim[0] + corr_plot_x_lim[1]) / 2, -0.55), ha='center', color='orange')\n",
    "        freq_plot.set_title(label=f'Frequency Distribution')\n",
    "        freq_plot.set_xticklabels(labels=freq_plot.get_xticklabels(), rotation=30)\n",
    "\n",
    "plot_1B()"
   ]
  },
  {
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "There is no need to create any new features in this dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Feature Selection\n",
    "\n",
    "There are 2 columns to be removed (stalk-root, veil-type):\n",
    "\n",
    "1.  Stalk-root, because there are many missing values (31%)\n",
    "2.  Veil-type, because it contains only 1 unique category"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns\n",
    "df.drop(labels=drop_cols, axis=1, inplace=True)\n",
    "df_build.drop(labels=drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Encoding the data\n",
    "\n",
    "The data has only categorical text variables, therefore they have to be converted to numeric form.\n",
    "\n",
    "Between label encoding and one-hot encoding, one-hot encoding makes more sense as the categorical variables are nominal rather than ordinal."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (One-Hot) Encode the dataset (categorical -> binary)\n",
    "df_build = pd.get_dummies(data=df_build, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all the possible feature values are accounted for\n",
    "print(f'Shape of data subset:\\t\\t{df_build.shape}')\n",
    "print(f'Shape of entire dataset:\\t{pd.get_dummies(data=df, drop_first=True).shape}')"
   ]
  },
  {
   "source": [
    "### Inspect correlation after encoding\n",
    "\n",
    "The absence of odour seems to be very negatively correlated to a mushroom being poisonous.\n",
    "\n",
    "Perhaps it would be a good indicator of a mushroom being edible."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlation between top 10 factors and target variable (class)\n",
    "df_build.corr()['class_poisonous'].drop(labels='class_poisonous').sort_values(key=lambda x: np.abs(x), ascending=False).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi2-based feature selection\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Get top 10 factors that are correlated with the target variable (class)\n",
    "best_features_chi2 = SelectKBest(score_func=chi2, k=10).fit(X=df_build.drop(labels='class_poisonous', axis=1), y=df_build['class_poisonous'])\n",
    "best_features_mask = best_features_chi2.get_support()\n",
    "best_features = df_build.drop(labels='class_poisonous', axis=1).columns.values[best_features_mask]\n",
    "best_features_scores = best_features_chi2.scores_[best_features_mask]\n",
    "good_predictors = pd.Series(data=best_features_scores, index=best_features)\n",
    "\n",
    "good_predictors.sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "### Data Partitioning\n",
    "\n",
    "Split the build data into X and y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X = df_build.drop(labels='class_poisonous', axis=1)\n",
    "y = df_build['class_poisonous']"
   ]
  },
  {
   "source": [
    "### Algorithm Selection & Hyper-Parameter Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Determine best candidate algorithm using GridSearch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How did you select which learning algorithms to use?\n",
    "\n",
    "```\n",
    "    GridSearchCV was used, and the algorithm used was included within the parameter space.\n",
    "    For each algorithm, 6 different combinations of key hyperparameters were tested.\n",
    "    Out of all the combinations, the best performing algorithm was selected.\n",
    "    In this case, the algorithm is logistic regression.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate classification algorithms\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent classes for custom transformers\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a placeholder estimator class for use with GridSearchCV\n",
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_clf():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('clf', DummyEstimator())\n",
    "    ])\n",
    "\n",
    "    params = [\n",
    "        {\n",
    "            'clf': [KNeighborsClassifier()],\n",
    "            'clf__n_neighbors': np.arange(3, 14, 2)\n",
    "        },\n",
    "        {\n",
    "            'clf': [LogisticRegression()],\n",
    "            'clf__solver': ['liblinear', 'newton-cg'],\n",
    "            'clf__C': np.logspace(-3, 3, 3),\n",
    "            'clf__multi_class': ['ovr']\n",
    "        },\n",
    "        {\n",
    "            'clf': [CategoricalNB()],\n",
    "            'clf__alpha': np.logspace(-3, 3, 6)\n",
    "        },\n",
    "        {\n",
    "            'clf': [SVC()],\n",
    "            'clf__kernel': ['rbf', 'linear'],\n",
    "            'clf__C': np.logspace(-3, 4, 3)\n",
    "        },\n",
    "        {\n",
    "            'clf': [DecisionTreeClassifier()],\n",
    "            'clf__max_depth': [10, 20, 30],\n",
    "            'clf__min_samples_leaf': [10, 30]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    best_clf_algo = GridSearchCV(estimator=pipe, param_grid=params, cv=3)\n",
    "    best_clf_algo.fit(X=X, y=y)\n",
    "    return best_clf_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "# pickle.dump(obj=grid_search_clf(), file=open('./models/best_clf_algo.p', 'wb'))\n",
    "\n",
    "# Load result\n",
    "best_clf_algo_loaded = pickle.load(file=open('./models/best_clf_algo.p', 'rb'))\n",
    "\n",
    "# Inspect result\n",
    "print(best_clf_algo_loaded.best_estimator_)\n",
    "gs_clf = pd.DataFrame(best_clf_algo_loaded.cv_results_)\n",
    "gs_clf.sort_values(by='rank_test_score')"
   ]
  },
  {
   "source": [
    "#### Determine best hyperparameters for selected algorithm using GridSearch\n",
    "\n",
    "Selected Algorithm: Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   Did you try to tune the hyper parameters of the learning algorithm, and in that case how?\n",
    "\n",
    "```\n",
    "    Yes. GridSearchCV was used once again, but since the logistic regression algorithm\n",
    "    had already been selected, more hyperparameters specific to logistic regression could be tested.\n",
    "    \n",
    "    Standardization was also compared against no scaling.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyScaler(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X"
   ]
  },
  {
   "source": [
    "SVC performs as well as before, with an accuracy of roughly 1.0."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_tuning():\n",
    "    global X, y\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('clf', SVC())\n",
    "    ])\n",
    "\n",
    "    params = {\n",
    "        'clf__kernel': ['linear'],\n",
    "        'clf__C': np.logspace(-3, 3, 3),\n",
    "        'clf__tol': [1e-5, 1e-4]\n",
    "    }\n",
    "\n",
    "    return GridSearchCV(estimator=pipe, param_grid=params, cv=3).fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get result\n",
    "svc_tuned = svc_tuning()\n",
    "\n",
    "# Inspect result\n",
    "print(svc_tuned.best_params_)\n",
    "pd.DataFrame(svc_tuned.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_clf_params():\n",
    "    global X, y\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', DummyScaler()),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    params = {\n",
    "            'scaler': ['passthrough', StandardScaler()],\n",
    "            'clf__solver': ['liblinear', 'saga'],\n",
    "            'clf__tol': np.logspace(-5, 2, 3),\n",
    "            'clf__C': np.logspace(-4, 4, 5),\n",
    "            'clf__multi_class': ['ovr']\n",
    "    }\n",
    "\n",
    "    best_clf_params = GridSearchCV(estimator=pipe, param_grid=params, cv=5, n_jobs=-1)\n",
    "    best_clf_params.fit(X=X, y=y)\n",
    "    return best_clf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "# pickle.dump(obj=grid_search_clf_params(), file=open('./models/best_clf_params.p', 'wb'))\n",
    "\n",
    "# Load result\n",
    "best_clf_params = pickle.load(file=open('./models/best_clf_params.p', 'rb'))\n",
    "\n",
    "# Inspect result\n",
    "print(best_clf_params.best_params_)\n",
    "gs_clf_params = pd.DataFrame(best_clf_params.cv_results_)\n",
    "gs_clf_params.sort_values(by='rank_test_score')"
   ]
  },
  {
   "source": [
    "No scaler is needed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Combining Everything\n",
    "\n",
    "<a id=\"classification-finale\" /></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Building Pipeline\n",
    "<br>\n",
    "Build a machine learning pipeline, using\n",
    "\n",
    "*   a custom feature-selection transformer,\n",
    "*   a one-hot encoder,\n",
    "*   the most consistent algorithm,\n",
    "*   the best performing hyperparameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_redundant_cols_1(df: pd.DataFrame):\n",
    "    return df.drop(labels=drop_cols, axis=1, errors='ignore')\n",
    "\n",
    "def ensure_target_absence_1(df: pd.DataFrame):\n",
    "    return df.drop(labels='class', axis=1)\n",
    "\n",
    "class FeatureSelector1(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.has_target_variable: bool = False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if 'class' in X.columns.values:\n",
    "            self.has_target_variable = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = drop_redundant_cols_1(X)\n",
    "        if self.has_target_variable:\n",
    "            X_copy = ensure_target_absence_1(X_copy)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Specify all possible column values for dataset\n",
    "def get_column_values_1(df: pd.DataFrame):\n",
    "    categories = []\n",
    "    for i in df.drop(labels=['class', *drop_cols], axis=1, errors='ignore').columns.values:\n",
    "        categories.append(pd.unique(df[i]))\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    ('feature_selector', FeatureSelector1()),\n",
    "    ('encoder', OneHotEncoder(drop='first', categories=get_column_values_1(df))),\n",
    "    ('classifier', LogisticRegression(C=100.0, multi_class='ovr', solver='liblinear', tol=1e-05))\n",
    "])"
   ]
  },
  {
   "source": [
    "### Model Training\n",
    "\n",
    "Fit the data to the pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X=X_build, y=y_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# pickle.dump(obj=model, file=open('./models/final_classifier.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "final_classifier = pickle.load(file=open('./models/final_classifier.p', 'rb'))"
   ]
  },
  {
   "source": [
    "### Model Scoring\n",
    "\n",
    "Use the model to generate predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_classifier.predict(X=X_final)\n",
    "y_pred"
   ]
  },
  {
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Evaluate the performance of the final model based on standard classification metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How do you evaluate the quality of your system?\n",
    "\n",
    "```\n",
    "    The machine learning pipeline was evaluated against:\n",
    "    1.  the train set,\n",
    "    2.  the test set,\n",
    "    3.  the entire dataset\n",
    "\n",
    "    in terms of:\n",
    "    1.  accuracy,\n",
    "    2.  precision,\n",
    "    3.  recall,\n",
    "    4.  f1-score\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model evaluation dependencies\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "source": [
    "#### Evaluate against build set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_build_pred = final_classifier.predict(X=X_build)\n",
    "\n",
    "# Classification summary\n",
    "print(classification_report(y_true=y_build, y_pred=y_build_pred, target_names=['edible', 'poisonous']))\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\n', pd.DataFrame(data=confusion_matrix(y_true=y_build, y_pred=y_build_pred, labels=['edible', 'poisonous']), index=['Actual Edible', 'Actual Poisonous'], columns=['Predicted Edible', 'Predicted Poisonous']), '\\n\\n', sep='')\n",
    "\n",
    "# Print target distribution in y_build\n",
    "print(y_build.groupby(y_build).count())"
   ]
  },
  {
   "source": [
    "#### Evaluate against final set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How do you evaluate the quality of your system?\n",
    "\n",
    "```\n",
    "    To check for overfitting, the accuracy score for the build and final sets were compared.\n",
    "    They were approximately within 1% of each other (~0.99 and ~0.99)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How well does your system compare to a stupid baseline?\n",
    "\n",
    "```\n",
    "    My machine learning pipeline predicts correctly (~0.99) almost\n",
    "    twice as frequently as compared to a stupid baseline (~0.50)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   Can you say anything about the errors that the system makes? For a classification task, you may consider a confusion matrix.\n",
    "\n",
    "```\n",
    "    My machine learning pipeline is quite accurate, so there are few to no errors.\n",
    "    Using the confusion matrix as seen below, all the samples (mushrooms) in the test set\n",
    "    were correctly categorised as 'edible' or 'poisonous' respectively.\n",
    "\n",
    "    Recall is also 1.00. That means that all the poisonous mushrooms were successfully identified.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification summary\n",
    "print(classification_report(y_true=y_final, y_pred=y_pred, target_names=['edible', 'poisonous']))\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\n', pd.DataFrame(data=confusion_matrix(y_true=y_final, y_pred=y_pred, labels=['edible', 'poisonous']), index=['Actual Edible', 'Actual Poisonous'], columns=['Predicted Edible', 'Predicted Poisonous']), '\\n\\n', sep='')\n",
    "\n",
    "# Print target distribution in y_final\n",
    "print(y_final.groupby(y_final).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy baseline for classification\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy='uniform')\n",
    "dummy.fit(X_build, y_build)\n",
    "dummy.score(X_final, y_final)"
   ]
  },
  {
   "source": [
    "#### Evaluate against entire dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_whole_pred = final_classifier.predict(X=X_whole)\n",
    "\n",
    "# Classification summary\n",
    "print(classification_report(y_true=y_whole, y_pred=y_whole_pred, target_names=['edible', 'poisonous']))\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\n', pd.DataFrame(data=confusion_matrix(y_true=y_whole, y_pred=y_whole_pred, labels=['edible', 'poisonous']), index=['Actual Edible', 'Actual Poisonous'], columns=['Predicted Edible', 'Predicted Poisonous']), '\\n\\n', sep='')\n",
    "\n",
    "# Print target distribution in y_whole\n",
    "print(y_whole.groupby(y_whole).count())"
   ]
  },
  {
   "source": [
    "*   Is it possible to say something about which features the model considers\n",
    "important? (Whether this is possible depends on the type of classifier\n",
    "you are using)\n",
    "\n",
    "```\n",
    "    The model does produce numerical coefficients, but these are not directly indicative of the\n",
    "    feature importances, as the features have been encoded.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_coefs_1():\n",
    "    global df, final_classifier\n",
    "    coefs = final_classifier['classifier'].coef_.reshape((-1,))\n",
    "    final_features = pd.get_dummies(FeatureSelector1().fit_transform(df), drop_first=True).columns.values\n",
    "    feature_coefs = pd.Series(data=coefs, index=final_features)\n",
    "    return feature_coefs\n",
    "\n",
    "get_feature_coefs_1().sort_values(ascending=False, key=lambda x: np.abs(x))"
   ]
  },
  {
   "source": [
    "## Part B > Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How is your prediction task defined? And what is the meaning of the output variable?\n",
    "\n",
    "```\n",
    "    The task is to predict the selling price of a house,\n",
    "    given its properties (i.e. number of bedrooms, floor area, etc.)\n",
    "\n",
    "    The output variable is measured in USD, and is the predicted price of a house in King County\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import Data\n",
    "\n",
    "Load data about King County house sales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How do you represent your data as features?\n",
    "\n",
    "```\n",
    "    The features are represented as columns in a pandas DataFrame\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   Did you bring in any additional sources of data?\n",
    "\n",
    "```\n",
    "    No, no external sources of data were used\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from a csv file\n",
    "df2 = pd.read_csv('./data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_whole = df2.drop(labels='price', axis=1)\n",
    "y2_whole = df2['price']\n",
    "X2_build, X2_final, y2_build, y2_final = train_test_split(X2_whole, y2_whole, test_size=0.2, random_state=4)\n",
    "df2_build = pd.concat(objs=(X2_build, y2_build), axis=1)"
   ]
  },
  {
   "source": [
    "#### Inspect Data\n",
    "\n",
    "Preview a sample of the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the top 10 rows of the dataset\n",
    "df2.head(n=10)"
   ]
  },
  {
   "source": [
    "#### Summarize Data\n",
    "\n",
    "Get a sense of the features involved"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect overview of the dataset\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect statistics of the dataset\n",
    "df2.describe().transpose().round(2)"
   ]
  },
  {
   "source": [
    "### Pre-Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   Did you process the features in any way?\n",
    "\n",
    "```\n",
    "    Yes, the features underwent (feature) engineering and selection,\n",
    "    logarithmic transformation, and standardization.\n",
    "\n",
    "    In addition, the target also underwent square root transformation.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Exploratory Data Analysis (EDA)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to keep track of variables to be removed\n",
    "drop_cols_2 = []\n",
    "\n",
    "# List to keep track of positively skewed variables\n",
    "positively_skewed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df2.isna().sum(axis=0)\n",
    "\n",
    "# There doesn't seem to be any missing values"
   ]
  },
  {
   "source": [
    "Visualize correlation amongst the original features using a heatmap\n",
    "\n",
    "`sqft_living`, `sqft_above`, `sqft_basement` and `sqft_lot` seem interrelated, especially `sqft_living` and `sqft_above` (suspiciously high correlation). As defined [here](https://rstudio-pubs-static.s3.amazonaws.com/155304_cc51f448116744069664b35e7762999f.html), `sqft_living` is the total interior floor area and it encapsulates `sqft_above`, `sqft_basement` and `sqft_lot`. To reduce collinearity, not all these features should be used to reduce overfitting.\n",
    "\n",
    "The id feature is not correlated to any other feature. If it is just an ordinary sequential id tag, it might be useless for our purposes as there isn't anything to generalize from id."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2A():\n",
    "    global df2\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(data=df2.corr(), cmap='RdBu', vmin=-1, vmax=1, ax=ax)\n",
    "    ax.set_title(label='Correlation Matrix')\n",
    "plot_2A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interrelated features may lead to overfitting\n",
    "\n",
    "# Course of action - drop columns\n",
    "drop_cols_2.extend(['sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_lot15'])"
   ]
  },
  {
   "source": [
    "Inspect distribution of the individual variables\n",
    "\n",
    "It can be seen that a few variables are positively skewed, such as `sqft_living` and `price`. Perhaps some (logarithmic/root) transformation could be applied to the data to make it conform more to a Normal distribution, which would improve the performance of most machine learning models.\n",
    "\n",
    "ID seems quite randomly distributed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2B():\n",
    "    global df2\n",
    "    for i in df2.columns.values:\n",
    "        if df2[i].dtype.kind in 'biufc':\n",
    "            with sns.axes_style(style='darkgrid'):\n",
    "                fig, (hst, bxp) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "                fig.suptitle(i.upper())\n",
    "                sns.histplot(data=df2, x=i, ax=hst, palette='deep')\n",
    "                sns.boxplot(data=df2, x=i, ax=bxp, palette='deep')\n",
    "plot_2B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many of the features seem to be positively skewed\n",
    "\n",
    "# Course of action - log/sqrt transformation\n",
    "positively_skewed.extend(['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'long', 'sqft_living15', 'sqft_lot15'])"
   ]
  },
  {
   "source": [
    "Inspect distributions of the transformed features, including `price`\n",
    "\n",
    "Logarithmic transformation seems to have the greatest impact in conforming the data to a Normal distribution. Nevertheless, we would have to test out both (log/root) transformations in a grid search to see which actually performs better."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2C():\n",
    "    global df2, positively_skewed\n",
    "    for i in positively_skewed:\n",
    "        fig, (non, log, sqrt) = plt.subplots(ncols=3, figsize=(8, 3))\n",
    "        non.set_title(label='No Transformation')\n",
    "        log.set_title(label='After Log Transformation')\n",
    "        sqrt.set_title(label='After Sqrt Transformation')\n",
    "        sns.histplot(x=df2[i], ax=non)\n",
    "        sns.histplot(x=np.log1p(df2[i]), ax=log)\n",
    "        sns.histplot(x=np.sqrt(df2[i]), ax=sqrt)\n",
    "        plt.subplots_adjust(wspace=0.4)\n",
    "plot_2C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.corr()['price'].sort_values(key=lambda x: np.abs(x), ascending=False)"
   ]
  },
  {
   "source": [
    "Inspect id feature\n",
    "\n",
    "Id seems to be redundant in this case as it is merely a serialization tag."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check id data type\n",
    "print('ID data type:\\t\\t', df2['id'].dtype)\n",
    "\n",
    "# Compare the number of ids to the total number of records \n",
    "print('Number of unique IDs:\\t', pd.unique(df2['id']).size)\n",
    "print('Total no. of records:\\t', df2.shape[0], '\\n')\n",
    "\n",
    "# Check correlation between id and the rest of the variables\n",
    "print(df2.corr()['id'].sort_values(key=lambda x: np.abs(x), ascending=False))\n",
    "\n",
    "\n",
    "# id seems redundant\n",
    "\n",
    "# Course of action - drop column\n",
    "drop_cols_2.append('id')"
   ]
  },
  {
   "source": [
    "Inspect zipcode feature\n",
    "\n",
    "Zipcode may provide some information as to where the house is located or which neighbourhood it resides in. As some patterns could be derived from these data, it should not be removed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check zipcode data type\n",
    "print('zipcode data type:\\t\\t', df2['zipcode'].dtype)\n",
    "\n",
    "# Compare the number of zipcodes to the total number of records \n",
    "print('Number of unique zipcodes:\\t', pd.unique(df2['zipcode']).size)\n",
    "print('Total no. of records:\\t\\t', df2.shape[0], '\\n')\n",
    "\n",
    "# Check correlation between zipcode and the rest of the variables\n",
    "print(df2.corr()['zipcode'].sort_values(key=lambda x: np.abs(x), ascending=False))\n",
    "\n",
    "\n",
    "# zipcode does not seem redundant\n",
    "\n",
    "# Course of action - no action"
   ]
  },
  {
   "source": [
    "Inspect correlations between transformed features and untransformed target (`price`)\n",
    "\n",
    "The shapes of the correlations change when logarithmic or square root transformations are applied on the feature variables. Specifically, logarithmically transformed `sqft_living` seems to be positively exponentially related to untransformed `price`.\n",
    "\n",
    "No transformation should not be performed on `long` (longitude) as it yields no result.\n",
    "\n",
    "To counter the effects of the X transformations, y (`price`) should be transformed too. Nonetheless, we would have to test them with grid search later on to see which indeed performs the best."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D():\n",
    "    global df2, positively_skewed\n",
    "    for i in positively_skewed:\n",
    "        with sns.axes_style(style='whitegrid'):\n",
    "            fig, (bef, log, sqrt) = plt.subplots(ncols=3, figsize=(10, 5))\n",
    "            bef.set_title(label='No Transformation')\n",
    "            log.set_title(label='Log Transformation')\n",
    "            sqrt.set_title(label='Sqrt Transformation')\n",
    "            sns.scatterplot(data=df2, x=i, y='price', ax=bef)\n",
    "            sns.scatterplot(x=np.log1p(df2[i]), y=df2['price'], ax=log)\n",
    "            sns.scatterplot(x=np.sqrt(df2[i]), y=df2['price'], ax=sqrt)\n",
    "plot_2D()"
   ]
  },
  {
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "There seems to be useful extractable data in the `date` feature, such as the `year`, `month` and `day` on which the house was sold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month and day from the date feature\n",
    "df2_date = pd.to_datetime(df2['date'], yearfirst=True)\n",
    "df2['year'] = pd.DatetimeIndex(data=df2_date).year\n",
    "df2['month'] = pd.DatetimeIndex(data=df2_date).month\n",
    "df2['day'] = pd.DatetimeIndex(data=df2_date).day\n",
    "\n",
    "df2_build_date = pd.to_datetime(df2_build['date'], yearfirst=True)\n",
    "df2_build['year'] = pd.DatetimeIndex(data=df2_build_date).year\n",
    "df2_build['month'] = pd.DatetimeIndex(data=df2_build_date).month\n",
    "df2_build['day'] = pd.DatetimeIndex(data=df2_build_date).day\n",
    "\n",
    "# Date variable seems redundant now\n",
    "\n",
    "# Course of action - drop column\n",
    "drop_cols_2.append('date')"
   ]
  },
  {
   "source": [
    "#### Feature Selection\n",
    "\n",
    "Drop redundant columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review columns to be dropped\n",
    "drop_cols_2"
   ]
  },
  {
   "source": [
    "There are 6 columns to be removed (`id`, `date`, `sqft_lot`, `sqft_above`, `sqft_basement`, `sqft_lot15`):\n",
    "\n",
    "1.  id, because it is redundant\n",
    "2.  date, because its necessary components have been extracted\n",
    "3.  sqft_lot, sqft_above and sqft_basement, because they are related to sqft_living\n",
    "4.  sqft_lot15, because it is related to sqft_living15"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns\n",
    "df2.drop(labels=drop_cols_2, axis=1, inplace=True)\n",
    "df2_build.drop(labels=drop_cols_2, axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "### Data Partitioning\n",
    "\n",
    "Split the build data into X2 and y2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X2 = df2_build.drop(labels='price', axis=1)\n",
    "y2 = df2_build['price']"
   ]
  },
  {
   "source": [
    "### Algorithm Selection & Hyper-Parameter Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Determine best regression algorithm using GridSearch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How did you select which learning algorithms to use?\n",
    "\n",
    "```\n",
    "    GridSearchCV was used, and the algorithm used was one of the parameters.\n",
    "    For each algorithm, a maximum of 6 different combinations of key hyperparameters were tested.\n",
    "    Out of all the combinations, the best performing algorithm was selected.\n",
    "    \n",
    "    In this case, the algorithm is gradient boosting regressor,\n",
    "    which is an ensemble learning algorithm.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate regression algorithms\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_reg():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reg', DummyEstimator())\n",
    "    ])\n",
    "\n",
    "    params = [\n",
    "        {\n",
    "            'reg': [LinearRegression()],\n",
    "            'reg__normalize': [True, False],\n",
    "            'reg__fit_intercept': [True, False]\n",
    "        },\n",
    "        {\n",
    "            'reg': [Lasso(), Ridge()],\n",
    "            'reg__alpha': np.logspace(-5, 3, 6)\n",
    "        },\n",
    "        {\n",
    "            'reg': [DecisionTreeRegressor(), GradientBoostingRegressor()],\n",
    "            'reg__max_depth': np.arange(5, 11)\n",
    "        },\n",
    "        {\n",
    "            'reg': [KNeighborsRegressor()],\n",
    "            'reg__n_neighbors': np.arange(5, 11)\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    best_reg_algo = GridSearchCV(estimator=pipe, param_grid=params, cv=3, n_jobs=-1)\n",
    "    best_reg_algo.fit(X=X2, y=y2)\n",
    "    return best_reg_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "# pickle.dump(obj=grid_search_reg(), file=open('./models/best_reg_algo.p', 'wb'))\n",
    "\n",
    "# Inspect result\n",
    "best_reg_algo_loaded = pickle.load(file=open('./models/best_reg_algo.p', 'rb'))\n",
    "\n",
    "print(best_reg_algo_loaded.best_estimator_)\n",
    "gs_reg = pd.DataFrame(best_reg_algo_loaded.cv_results_)\n",
    "gs_reg.sort_values(by='rank_test_score')"
   ]
  },
  {
   "source": [
    "#### Determine best hyperparameters for selected algorithm using GridSearch\n",
    "\n",
    "Selected Algorithm: Gradient Boosting Regressor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   Did you try to tune the hyper parameters of the learning algorithm, and\n",
    "in that case how?\n",
    "\n",
    "```\n",
    "    Yes. GridSearchCV was used once again, but since the gradient boosting regressor algorithm\n",
    "    had already been selected, more hyperparameters specific to gradient boosting regressor could\n",
    "    be tested.\n",
    "\n",
    "    This was performed in 2 stages: a broad search and a finer tuning phase\n",
    "    \n",
    "    In this case, maximum depth, minimum samples for leaf nodes and for splits were tested.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_reg_params():\n",
    "    global X2, y2\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reg', GradientBoostingRegressor())\n",
    "    ])\n",
    "\n",
    "    params = {\n",
    "        'reg__max_depth': np.arange(2, 5),\n",
    "        'reg__min_samples_leaf': np.arange(9, 100, 30),\n",
    "        'reg__min_samples_split': np.arange(9, 100, 30)\n",
    "    }\n",
    "\n",
    "    best_reg_params = GridSearchCV(estimator=pipe, param_grid=params, cv=3, n_jobs=-1)\n",
    "    best_reg_params.fit(X=X2, y=y2)\n",
    "    return best_reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "# pickle.dump(obj=grid_search_reg_params(), file=open('./models/best_reg_params.p', 'wb'))\n",
    "\n",
    "# Inspect result\n",
    "best_reg_params = pickle.load(file=open('./models/best_reg_params.p', 'rb'))\n",
    "\n",
    "print(best_reg_params.best_params_)\n",
    "gs_reg_params = pd.DataFrame(best_reg_params.cv_results_)\n",
    "gs_reg_params.sort_values(by='rank_test_score')"
   ]
  },
  {
   "source": [
    "After the broad search was conducted, it seems that\n",
    "\n",
    "`{'reg__max_depth': 4, 'reg__min_samples_leaf': 9, 'reg__min_samples_split': 39}`\n",
    "\n",
    "performs the best. The hyper-parameter space can be narrowed down to values closer to 9 and 39."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_reg_params_2():\n",
    "    global X2, y2\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reg', GradientBoostingRegressor())\n",
    "    ])\n",
    "\n",
    "    params = {\n",
    "        'reg__max_depth': [4],\n",
    "        'reg__min_samples_leaf': np.arange(7, 10),\n",
    "        'reg__min_samples_split': [30, 40, 50]\n",
    "    }\n",
    "\n",
    "    best_reg_params = GridSearchCV(estimator=pipe, param_grid=params, cv=5, n_jobs=-1)\n",
    "    best_reg_params.fit(X=X2, y=y2)\n",
    "    return best_reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "# pickle.dump(obj=grid_search_reg_params_2(), file=open('./models/best_reg_params_2.p', 'wb'))\n",
    "\n",
    "# Inspect result\n",
    "best_reg_params_2 = pickle.load(file=open('./models/best_reg_params_2.p', 'rb'))\n",
    "\n",
    "print(best_reg_params_2.best_params_)\n",
    "gs_reg_params = pd.DataFrame(best_reg_params_2.cv_results_)\n",
    "gs_reg_params.sort_values(by='rank_test_score')"
   ]
  },
  {
   "source": [
    "Further tuning - Scaler, Normalizing X Transformer\n",
    "\n",
    "Custom X transformers were designed, to conform the positively skewed columns to more Normal distributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        all_cols = X.columns.values\n",
    "        for i in positively_skewed:\n",
    "            if i != 'long' and i not in drop_cols_2:\n",
    "                X_copy[i] = np.log1p(X[i])\n",
    "        return X_copy\n",
    "\n",
    "class SqrtTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        all_cols = X.columns.values\n",
    "        for i in positively_skewed:\n",
    "            if i != 'long' and i not in drop_cols_2:\n",
    "                X_copy[i] = np.sqrt(X[i])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_transformer():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('trans', DummyTransformer()),\n",
    "        ('scaler', DummyScaler()),\n",
    "        ('reg', GradientBoostingRegressor(\n",
    "            max_depth=4,\n",
    "            min_samples_leaf=7,\n",
    "            min_samples_split=30\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    params = {\n",
    "        'trans': ['passthrough', LogTransformer(), SqrtTransformer()],\n",
    "        'scaler': ['passthrough', StandardScaler(), RobustScaler()]\n",
    "    }\n",
    "\n",
    "    best_trans_params = GridSearchCV(estimator=pipe, param_grid=params, cv=5, n_jobs=-1)\n",
    "    best_trans_params.fit(X=X2, y=y2)\n",
    "    return best_trans_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "# pickle.dump(obj=best_transformer(), file=open('./models/best_reg_trans.p', 'wb'))\n",
    "\n",
    "# Inspect result\n",
    "best_reg_trans = pickle.load(file=open('./models/best_reg_trans.p', 'rb'))\n",
    "\n",
    "print(best_reg_trans.best_params_)\n",
    "gs_reg_trans = pd.DataFrame(best_reg_trans.cv_results_)\n",
    "gs_reg_trans.sort_values(by='rank_test_score')"
   ]
  },
  {
   "source": [
    "Further tuning - Normalizing y Transformer\n",
    "\n",
    "To counter the effects of X transformation, the target variable (y) could be transformed too"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_tune_reg(cv: int = 4):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('trans', LogTransformer()),\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('reg', GradientBoostingRegressor(max_depth=4, min_samples_leaf=7, min_samples_split=30))\n",
    "    ])\n",
    "\n",
    "    sqrt_y = TransformedTargetRegressor(regressor=pipe, func=np.sqrt, inverse_func=np.square)\n",
    "\n",
    "    log_y = TransformedTargetRegressor(regressor=pipe, func=np.log1p, inverse_func=np.expm1)\n",
    "\n",
    "    scores = []\n",
    "    for m in (pipe, sqrt_y, log_y):\n",
    "        scores.append(cross_val_score(estimator=m, X=X2, y=y2, cv=cv))\n",
    "    result = pd.DataFrame(data=scores, columns=[f'Test {i + 1}' for i in range(cv)], index=['no y transformation', 'sqrt y transformation', 'log y transformation'])\n",
    "    result['Mean Score'] = result.mean(axis=1)\n",
    "    result['Std Score'] = result.std(axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "# pickle.dump(obj=further_tune_reg(), file=open('./models/best_reg_y_trans.p', 'wb'))\n",
    "\n",
    "# Inspect result\n",
    "best_reg_y_trans = pickle.load(file=open('./models/best_reg_y_trans.p', 'rb'))\n",
    "\n",
    "print(best_reg_y_trans.sort_values(by='Mean Score', ascending=False))"
   ]
  },
  {
   "source": [
    "### Combining Everything\n",
    "\n",
    "<a id=\"regression-finale\" /></a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Building the pipeline\n",
    "<br>\n",
    "Build the machine learning pipeline, using\n",
    "\n",
    "*   a custom feature-engineering transformer,\n",
    "*   a custom feature-selection transformer,\n",
    "*   a custom logarithmic X transformer,\n",
    "*   a robust scaler,\n",
    "*   the most consistent algorithm (gradient boosting regressor),\n",
    "*   the best performing hyperparameters\n",
    "\n",
    "To further improve performance and reduce overfitting,<br>\n",
    "the target variable will be transformed too (sqrt)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_parts(df: pd.DataFrame, col: str, **kwargs):\n",
    "    df_datetime = pd.DatetimeIndex(df[col], **kwargs)\n",
    "    return df_datetime.year, df_datetime.month, df_datetime.day\n",
    "\n",
    "class FeatureEngineer2(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_year, X_month, X_day = extract_date_parts(df=X, col='date', yearfirst=True)\n",
    "        X_copy['year'] = X_year\n",
    "        X_copy['month'] = X_month\n",
    "        X_copy['day'] = X_day\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_redundant_cols_2(df: pd.DataFrame):\n",
    "    return df.drop(labels=drop_cols_2, axis=1, errors='ignore')\n",
    "\n",
    "def ensure_target_absence_2(df: pd.DataFrame):\n",
    "    return df.drop(labels='price', axis=1)\n",
    "\n",
    "class FeatureSelector2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.has_target_variable: bool = False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if 'price' in X.columns.values:\n",
    "            self.has_target_variable = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = drop_redundant_cols_2(X)\n",
    "        if self.has_target_variable:\n",
    "            X_copy = ensure_target_absence_2(X_copy)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "pipe2 = Pipeline(steps=[\n",
    "    ('feature_engineer', FeatureEngineer2()),\n",
    "    ('feature_selector', FeatureSelector2()),\n",
    "    ('sqrt_transformer', LogTransformer()),\n",
    "    ('standard_scaler', RobustScaler()),\n",
    "    ('regressor', GradientBoostingRegressor(max_depth=4, min_samples_leaf=7, min_samples_split=30))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap pipeline in a target transformer\n",
    "model2 = TransformedTargetRegressor(regressor=pipe2, func=np.sqrt, inverse_func=np.square, check_inverse=False)"
   ]
  },
  {
   "source": [
    "### Model Training\n",
    "\n",
    "Fit the data to the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X=X2_build, y=y2_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# pickle.dump(obj=model2, file=open('./models/final_regressor.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "final_regressor = pickle.load(file=open('./models/final_regressor.p', 'rb'))"
   ]
  },
  {
   "source": [
    "### Model Scoring\n",
    "\n",
    "Use the model to generate predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = final_regressor.predict(X2_final)\n",
    "y_pred_2"
   ]
  },
  {
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Evaluate the performance of the final model based on standard regression metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How do you evaluate the quality of your system?\n",
    "\n",
    "```\n",
    "    The machine learning pipeline was evaluated against:\n",
    "    1.  the train set,\n",
    "    2.  the test set,\n",
    "    3.  the entire dataset\n",
    "\n",
    "    in terms of:\n",
    "    1.  mean squared error,\n",
    "    2.  mean absolute error,\n",
    "    3.  r squared\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Import regression metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_report(y_true, y_pred, type: str):\n",
    "    print(\n",
    "f'''Regression Report ({type})\n",
    "================================\n",
    "MSE:\\t\\t{np.round(mean_squared_error(y_true=y_true, y_pred=y_pred), 2)}\n",
    "MAE:\\t\\t{np.round(mean_absolute_error(y_true=y_true, y_pred=y_pred), 2)}\n",
    "R2:\\t\\t{np.round(r2_score(y_true=y_true, y_pred=y_pred), 4)}\n",
    "''')"
   ]
  },
  {
   "source": [
    "#### Evaluate against build set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_report(y2_build, final_regressor.predict(X2_build), type='train')"
   ]
  },
  {
   "source": [
    "#### Evaluate against final set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How do you evaluate the quality of your system?\n",
    "\n",
    "```\n",
    "    To check for overfitting, the r2 score for the build and final sets were compared.\n",
    "    They were approximately within 5% of each other (~0.92 and ~0.88),\n",
    "    which indicates that the model is not overfitted.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   How well does your system compare to a stupid baseline?\n",
    "\n",
    "```\n",
    "    My machine learning pipeline predicts more accurately than a stupid baseline by a huge margin.\n",
    "\n",
    "    The r2 score (which describes how well the model fits the data) of my machine\n",
    "    learning pipeline is ~0.88 while that of a stupid baseline is negative\n",
    "    (absolutely bad fit with respect to the data).\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "*   Can you say anything about the errors that the system makes?\n",
    "\n",
    "```\n",
    "    Concerning a regression problem, it is impossible to predict an exact value with machine learning.\n",
    "    Therefore, the metrics by which a regression machine learning model is evaluated take into account\n",
    "    the margin of error which the model makes. For example, r2 shows the proportion of variance\n",
    "    (between a predicted value and the actual value) attributed to variance in the feature values.\n",
    "    Hence, an r2 score close to 1 suggests success for a machine learning model.\n",
    "\n",
    "    In this case 0.88 for a test score is considerably good.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_report(y2_final, y_pred_2, type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy baseline for regression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "dummy2 = DummyRegressor(strategy='median')\n",
    "dummy2.fit(X2_build, y2_build)\n",
    "dummy2.score(X2_final, y2_final)"
   ]
  },
  {
   "source": [
    "#### Evaluate against entire dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_report(y2_whole, final_regressor.predict(X2_whole), type='entire')"
   ]
  },
  {
   "source": [
    "#### Evaluate against entire dataset (visualization)\n",
    "\n",
    "The model seems to perform quite consistently within the 0.8 - 1.0 band, hovering around 0.9. For sample sizes of at least 500, the variation decreases further to produce a relatively stable horizontal line. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2E():\n",
    "    df2_new = pd.read_csv('./data/kc_house_data.csv')\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(16, 10))\n",
    "\n",
    "    for r in range(3):\n",
    "        for c in range(3):\n",
    "            df_tmp = df2_new.sample(frac=1)\n",
    "            scores = []\n",
    "            buffers = np.arange(100, 1000, 50)\n",
    "            for buf in buffers:\n",
    "                scores.append(final_regressor.score(df_tmp.drop('price', axis=1).iloc[:buf,:], df_tmp['price'].iloc[:buf]))\n",
    "            sns.lineplot(x=buffers, y=scores, color='black', ax=ax[r,c])\n",
    "            ax[r,c].set(\n",
    "                title=f'Test {r * 3 + c + 1}',\n",
    "                ylim=(0.4, 1.05),\n",
    "                yticks=np.arange(0.5, 1.05, 0.1),\n",
    "                ylabel='r2',\n",
    "                xticks=np.arange(0, 1001, 100),\n",
    "                xlabel='Buffer Size'\n",
    "            )\n",
    "            sns.lineplot(x=[0, 1000], y=[1.0] * 2, color='green', ax=ax[r,c])\n",
    "            sns.lineplot(x=[0, 1000], y=[0.9] * 2, color='orange', ax=ax[r,c])\n",
    "            sns.lineplot(x=[0, 1000], y=[0.8] * 2, color='red', ax=ax[r,c])\n",
    "            sns.lineplot(x=[500] * 2, y=[0.4, 1.], color='grey', ax=ax[r,c])\n",
    "    plt.subplots_adjust(hspace=0.45)\n",
    "\n",
    "plot_2E()"
   ]
  },
  {
   "source": [
    "*   Is it possible to say something about which features the model considers important?\n",
    "\n",
    "```\n",
    "    The more important features have greater values as seen below.\n",
    "    It seems grade, floor area and geographical coordinates are the most important features.\n",
    "\n",
    "    These roughly match our intuition, as floor area, quality of construction and design and\n",
    "    location are crucial factors when deciding which house to purchase.\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances_2():\n",
    "    global X2_build, final_regressor\n",
    "    impts = final_regressor.regressor_['regressor'].feature_importances_\n",
    "    final_features = FeatureSelector2().fit_transform(FeatureEngineer2().fit_transform(X2_build)).columns.values\n",
    "    feature_impts = pd.Series(data=impts, index=final_features)\n",
    "    return feature_impts\n",
    "\n",
    "get_feature_importances_2().sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "## Conclusions\n",
    "\n",
    "Every machine learning problem is different, and there is no one best algorithm to solve all.\n",
    "It is the data scientist's responsibility to experiment and select the most appropriate algorithm that is able to generalize patterns in the available data, and make accurate and precise predictions on new, unseen data. Nonetheless, that is just the beginning as there are hyperparameters to tune, transformations to be performed and overfitting to check for.\n",
    "\n",
    "In Part A, the [Logistic Regression algorithm](#classification-finale) was chosen, whereas in Part B, the [Gradient Boosting Regressor Ensemble algorithm](#regression-finale) was chosen instead. One-Hot Encoding was applied for Part A, while logarithmic and square root transformations were performed in Part B."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}