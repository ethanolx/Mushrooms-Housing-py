{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd006e46f44bb844bdd55de1af887732b14e875f5b0d2374a3f4b9484cbcb737e08",
   "display_name": "Python 3.8.5  ('.venv': pipenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "06e46f44bb844bdd55de1af887732b14e875f5b0d2374a3f4b9484cbcb737e08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "source": [
    "# AIML CA1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import General Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical Dependencies\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Graphing Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning Dependencies\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Miscellaneous Dependencies\n",
    "from typing import Callable, Dict # static typing\n",
    "\n",
    "# Utility Functions\n",
    "from utils.extraction import extract_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "## Utility Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Part I"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import Exclusive Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Classification Metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "source": [
    "### Import Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract raw content of ./data/agaricus-lepiota.names file\n",
    "metadata: str\n",
    "with open('./data/agaricus-lepiota.names') as f:\n",
    "    metadata = f.read()\n",
    "\n",
    "# Extract attributes from metadata\n",
    "attrs = extract_attributes(metadata, r'7\\. Attribute Information:.*\\n((.|\\n)*)8\\. Missing')\n",
    "\n",
    "# Extract column names to be used for dataframe\n",
    "cols = attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the dataframe from ./data/agaricus-lepiota.data file,\n",
    "#   using column names derived from ./data/agaricus-lepiota.names file\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='./data/agaricus-lepiota.data',\n",
    "    sep=',',\n",
    "    header=0,\n",
    "    names=cols\n",
    ")\n",
    "\n",
    "# Expand attribute codes to their full definitions\n",
    "for col in cols:\n",
    "    df[col].replace(to_replace=attrs[col] ,inplace=True)"
   ]
  },
  {
   "source": [
    "#### Inspect Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect top 10 rows of the dataset\n",
    "df.head(n=10)"
   ]
  },
  {
   "source": [
    "#### Summarize Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect overview of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect statistics of the dataset\n",
    "df.describe().transpose()"
   ]
  },
  {
   "source": [
    "### Pre-Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.describe().transpose()['unique']\n",
    "df_unique[df_unique < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels='veil-type', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(data=df, drop_first=True)\n",
    "df_ohe.corr()['class_poisonous'].sort_values(key=lambda x: np.abs(x), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Check correlation between attributes\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     yoyo = pd.get_dummies(df, drop_first=True)\n",
    "#     df_corr = yoyo.corr()\n",
    "#     df_corr_targ = df_corr\n",
    "#     df_minor_mask = df_corr_targ.apply(func=lambda s: np.abs(s['class_poisonous']) > 0.5)\n",
    "#     df_corr_sort = df_corr_targ[df_minor_mask].sort_values(by='class_poisonous', key=lambda s: -np.abs(s))\n",
    "#     # df_corr_sort.drop(labels='class_poisonous', inplace=True)\n",
    "#     targeted_corr = df_corr.loc[df_corr_sort.index.values, df_corr_sort.index.values]\n",
    "#     sns.pairplot(targeted_corr, hue='class_poisonous', diag_kind=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi square\n",
    "# from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# # t = pd.get_dummies(df, drop_first=True).groupby(by='class_poisonous').sum().astype(int)\n",
    "# t = pd.get_dummies(df).drop(labels='class_edible', axis=1)\n",
    "\n",
    "# s = SelectKBest(score_func=chi2, k=5).fit(t.drop(labels='class_poisonous', axis=1), t[['class_poisonous']])\n",
    "# good_preds = t.drop(labels='class_poisonous', axis=1).columns.values[s.get_support()]\n",
    "# sns.pairplot(data=t.drop(labels=t.columns.values[t.columns.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdf = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import format_label\n",
    "def plot_A(df: pd.DataFrame):\n",
    "    ax = sns.countplot(data=df, x='class', palette='deep')\n",
    "    ax.set_ylim(top=5000)\n",
    "    ax.set_title(label='General Data Distribution')\n",
    "    ax.set_ylabel(ylabel='Number of Records')\n",
    "    ax.set_yticklabels(labels=format_label(\n",
    "        ax.get_yticks() / 1000, lambda s: f'{round(s)}k'))\n",
    "    ax.set_xlabel(xlabel='Type')\n",
    "    total_count = df.shape[0]\n",
    "    for p in ax.patches:\n",
    "        x = p.get_x()\n",
    "        y = p.get_height()\n",
    "        ax.annotate(text=f'{y} ({y/total_count*100:.1f}%)',\n",
    "                    xy=(x + 0.21, y + 70))\n",
    "    return ax\n",
    "ax_a = plot_A(df=df)\n",
    "ax_a"
   ]
  },
  {
   "source": [
    "### Data Partitioning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ohe.drop(labels='class_poisonous', axis=1)\n",
    "y = df_ohe['class_poisonous']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "source": [
    "### Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)\n",
    "# confusion_matrix(y_test, knn.predict(X_test))\n",
    "# knn.predict(X_test.iloc[0:1,:])\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours_range = list(range(1, 20))\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=len(neighbours_range), sharey=True)\n",
    "result = np.empty(shape=(0,))\n",
    "for neighbours in neighbours_range:\n",
    "    cv = cross_val_score(estimator=KNeighborsClassifier(n_neighbors=neighbours), X=X, y=y, cv=8)\n",
    "    # print(f\"Neighbours: {neighbours}\\t| Mean: {cv.mean()}\\t| Median: {np.median(cv)}\")\n",
    "    result = np.hstack((result, np.array([cv.mean()])))\n",
    "    # sns.swarmplot(y=cv, ax=ax[neighbours - 3])\n",
    "\n",
    "sns.lineplot(x=neighbours_range, y=result)\n",
    "print(result)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.base import BaseEstimator\n",
    "\n",
    "# class DummyEstimator(BaseEstimator):\n",
    "#     def fit(self): pass\n",
    "#     def score(self): pass\n",
    "\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     ('clf', DummyEstimator())\n",
    "# ])\n",
    "\n",
    "# params = [\n",
    "#     {\n",
    "#         'clf': [KNeighborsClassifier()],\n",
    "#         'clf__n_neighbors': np.arange(start=4, stop=10)\n",
    "#     },\n",
    "#     {\n",
    "#         'clf': [LogisticRegression(solver='newton-cg')],\n",
    "#         'clf__C': np.logspace(-1, 2, 3)\n",
    "#     },\n",
    "#     {\n",
    "#         'clf': [GaussianNB()]\n",
    "#     },\n",
    "#     {\n",
    "#         'clf': [SVC()],\n",
    "#         'clf__C': np.logspace(-1, 2, 3)\n",
    "#     },\n",
    "#     {\n",
    "#         'clf': [DecisionTreeClassifier()],\n",
    "#         'clf__max_depth': [10, 20, 30]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# cv = GridSearchCV(estimator=pipeline, param_grid=params, cv=5)\n",
    "# cv.fit(X=X, y=y)\n",
    "# import pickle\n",
    "# pickle.dump(obj=cv, file=open(\"./models/grid_search_clf.p\", \"wb\"))\n",
    "# print(cv.best_params_)\n",
    "# print(cv.best_score_)\n",
    "# print(cv.best_estimator_)\n",
    "# pd.DataFrame(data=cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "mod = pickle.load(file=open('./models/grid_search_clf.p'))\n",
    "mod.cv_results_"
   ]
  },
  {
   "source": [
    "## Part II"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Import Exclusive Dependencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Models (Regression)\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "source": [
    "### Import Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df2 = pd.read_csv('./data/kc_house_data.csv')"
   ]
  },
  {
   "source": [
    "#### Inspect Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.corr()"
   ]
  },
  {
   "source": [
    "#### Summarize Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe().transpose().round(2)"
   ]
  },
  {
   "source": [
    "### Pre-Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df2.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data=df2.corr(), cmap='RdBu', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.corr()['price'].sort_values(key=lambda x: np.abs(x), ascending=False).drop(['lat', 'long', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df2['id']).size, df2.count()['id'])\n",
    "df2.drop(labels='id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.unique(df2['zipcode']).size, df2.count()['zipcode'])\n",
    "sns.relplot(data=df2, x='zipcode', y='price')\n",
    "df2.drop(labels='zipcode', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=4)\n",
    "d = np.array(ax).reshape((-1))\n",
    "for i, t in enumerate(['waterfront', 'floors', 'yr_renovated', 'sqft_lot', 'sqft_lot15', 'yr_built', 'condition']):\n",
    "    sns.scatterplot(data=df2, x=t, y='price', ax=d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(labels=['waterfront', 'floors', 'yr_renovated', 'yr_built', 'condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_B(df: pd.DataFrame):\n",
    "    top_features = df.corr()['price'].sort_values(key=lambda x: np.abs(x), ascending=False).drop(['lat', 'long', 'price'])[:9].index.values\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(8, 6))\n",
    "    axs = np.array(ax).reshape((-1))\n",
    "    for i, x in enumerate(top_features):\n",
    "        sns.scatterplot(data=df, x=x, y='price', ax=axs[i])\n",
    "    return fig\n",
    "f = plot_B(df2)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date'] = pd.to_datetime(arg=df2['date'], yearfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df2, x='sqft_living', y='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df2, x='grade', y='price')\n",
    "sns.scatterplot(data=df2, x='grade', y='price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df2, x='bedrooms', y='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_tmp, x='bedrooms', y='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers\n",
    "outliers2 = df2[df2['']]"
   ]
  },
  {
   "source": [
    "#### Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#### Feature Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_corr = df2.corr()\n",
    "df2_corr.drop(labels=df2_corr.columns[df2_corr.columns != 'price'].values, axis=1).drop(labels='price', axis=0)['price'].sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "### Data Partitioning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df2[['sqft_living', 'grade', 'sqft_above', 'sqft_living15', 'bathrooms', 'view', 'sqft_basement', 'bedrooms', 'waterfront']]\n",
    "y2 = df2['price']\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2)\n",
    "from sklearn.preprocessing import RobustScaler, normalize\n",
    "#! delete !#\n",
    "pip = Pipeline(steps=[\n",
    "    ('scaler', normalize),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "model2 = LinearRegression()\n",
    "pip.fit(X=X2_train, y=y2_train)\n",
    "print(pip.score(X2_train, y2_train))\n",
    "print(pip.score(X2_test, y2_test))"
   ]
  },
  {
   "source": [
    "### Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LinearRegression()\n",
    "model2.fit(X=X2_train, y=y2_train)\n",
    "print(model2.score(X2_train, y2_train))\n",
    "print(model2.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BayesianRidge()\n",
    "model2.fit(X=X2_train, y=y2_train)\n",
    "print(model2.score(X2_train, y2_train))\n",
    "print(model2.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "u = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reg', DummyEstimator())\n",
    "])\n",
    "for m in [Ridge, Lasso, ElasticNet]:\n",
    "    p = m(alpha=0.5)\n",
    "    try:\n",
    "        p.fit(X2_train, y2_train)\n",
    "        print(p.score(X2_test, y2_test))\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "source": [
    "### Model Scoring"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Conclusions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}